name: Cow BFF (CD)

concurrency: prod_environment 

on:
  push:
    branches:
      # Set your base branch name here
      - dais24-main

jobs:
  unit-tests:
    name: "Unit tests"
    environment: Prod
    runs-on: ubuntu-latest
    env:
      DATABRICKS_CLUSTER_ID: ${{ vars.DATABRICKS_CLUSTER_ID }} # The spark unit test will run on this cluster via databricks-connect
      DATABRICKS_HOST: ${{ vars.DATABRICKS_HOST }} # The spark unit test will run on this workspace via databricks-connect
      ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }} # uses a service principal for databricks-connect
      ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }} # uses a service principal for databricks-connect
      ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }} # uses a service principal for databricks-connect

    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      - run: pip install -r requirements.txt
      - name: Run unit tests
        run: pytest -s -v tests/ --disable-warnings 

  deploy:
    name: "Deploy bundle and run notebook"
    environment: Prod
    runs-on: ubuntu-latest
    env:
      ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }} # service principal to trigger the DAB deployment and run
      ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }} # service principal to trigger the DAB deployment and run
      ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }} # service principal to trigger the DAB deployment and run

    steps:
      - uses: actions/checkout@v3
      - uses: databricks/setup-cli@main
      - name: Deploy bundle
        run: databricks bundle deploy --target production
      - name: Run notebook
        run: databricks bundle --target production run daily_report